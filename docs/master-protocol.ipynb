{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the SmartTag models\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls data4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-neo2xml --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-eval --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of corpus of xml documents and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-neo2xml -l10000 -f 181203all # on large sd-graph with 30000 panels from 1100 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-ocr # run only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='molecule']\" \\\n",
    "-f 3X_L600_molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_molecule \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o small_molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved as `3X_L600_molecule_small_molecule_2018-12-05-12-49.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_molecule_small_molecule_2018-12-05-12-49.zip rack/small_molecule.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='gene']\",\".//sd-tag[@type='protein']\" \\\n",
    "-f 3X_L600_geneprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_geneprod \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o geneprod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model saved under `3X_L600_geneprod_geneprod_2018-12-05-00-32.sddl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_geneprod_geneprod_2018-12-05-00-32.zip rack/geneprod.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_geneprod_2018-12-05-00-32.zip, testset: 3X_L600_geneprod, tokenization: False\n",
      "opt from model namebase=3X_L600_geneprod; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['geneprod']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [21]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "13977 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'geneprod' (geneprod), and shuffling 13977 examples.\n",
      "Generating dataset with 13977 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 5457 in position 13976))\n",
      "done\n",
      "\n",
      "0.000 0.032 1.000 0.062\n",
      "0.100 0.685 0.931 0.790\n",
      "0.200 0.751 0.894 0.816\n",
      "0.300 0.792 0.859 0.824\n",
      "0.400 0.823 0.822 0.823\n",
      "0.500 0.849 0.782 0.814\n",
      "0.600 0.874 0.735 0.798\n",
      "0.700 0.897 0.674 0.770\n",
      "0.800 0.921 0.588 0.718\n",
      "0.900 0.950 0.436 0.597\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod -m 3X_L600_geneprod_geneprod_2018-12-05-00-32.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_geneprod_2018-12-05-00-32.zip, testset: 3X_L600_geneprod, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [21]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "12249 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'geneprod' (geneprod), and shuffling 12249 examples.\n",
      "Generating dataset with 12249 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 12222 in position 12248)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 94\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_geneprod/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_geneprod_geneprod_2018-12-05-00-32.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8293921947479248.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8131826519966125.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8212074637413025.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'geneprod' (geneprod)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8293921947479248.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8131826519966125.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8212074637413025.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod -m 3X_L600_geneprod_geneprod_2018-12-05-00-32.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subcellular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='subcellular']\" \\\n",
    "-f 3X_L600_subcellular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_subcellular \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o subcellular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save as `3X_L600_subcellular_subcellular_2018-12-05-18-25.sddl` (size: 100167)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_subcellular_subcellular_2018-12-05-18-25.zip rack/subcellular.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_subcellular_subcellular_2018-12-05-18-25.zip, testset: 3X_L600_subcellular, tokenization: False\n",
      "opt from model namebase=3X_L600_subcellular; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['subcellular']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [3]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "3678 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'subcellular' (subcellular), and shuffling 3678 examples.\n",
      "Generating dataset with 3678 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 939 in position 3677))\n",
      "done\n",
      "\n",
      "0.000 0.031 1.000 0.060\n",
      "0.100 0.656 0.828 0.732\n",
      "0.200 0.745 0.784 0.764\n",
      "0.300 0.792 0.756 0.773\n",
      "0.400 0.825 0.731 0.775\n",
      "0.500 0.851 0.704 0.771\n",
      "0.600 0.877 0.670 0.760\n",
      "0.700 0.903 0.622 0.737\n",
      "0.800 0.930 0.554 0.695\n",
      "0.900 0.957 0.440 0.603\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_subcellular -m 3X_L600_subcellular_subcellular_2018-12-05-18-25.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_subcellular_subcellular_2018-12-05-18-25.zip, testset: 3X_L600_subcellular, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [3]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "3303 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'subcellular' (subcellular), and shuffling 3303 examples.\n",
      "Generating dataset with 3303 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 2588 in position 3302)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 24\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_subcellular/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_subcellular_subcellular_2018-12-05-18-25.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7896410226821899.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6865929365158081.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7345203757286072.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'subcellular' (subcellular)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7896410226821899.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6865929365158081.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7345203757286072.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_subcellular -m 3X_L600_subcellular_subcellular_2018-12-05-18-25.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='cell']\" \\\n",
    "-f 3X_L600_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_cell \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_cell_cell_2018-12-06-18-05.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_cell_cell_2018-12-06-18-05.zip rack/cell.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_cell_cell_2018-12-06-18-05.zip, testset: 3X_L600_cell, tokenization: False\n",
      "opt from model namebase=3X_L600_cell; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['cell']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [4]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "8499 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'cell' (cell), and shuffling 8499 examples.\n",
      "Generating dataset with 8499 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 6248 in position 8498)\n",
      "done\n",
      "\n",
      "0.000 0.014 1.000 0.027\n",
      "0.100 0.634 0.887 0.739\n",
      "0.200 0.718 0.856 0.781\n",
      "0.300 0.765 0.831 0.797\n",
      "0.400 0.798 0.808 0.803\n",
      "0.500 0.824 0.787 0.805\n",
      "0.600 0.847 0.764 0.804\n",
      "0.700 0.868 0.736 0.797\n",
      "0.800 0.891 0.696 0.782\n",
      "0.900 0.917 0.616 0.737\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_cell -m 3X_L600_cell_cell_2018-12-06-18-05.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_cell_cell_2018-12-06-18-05.zip, testset: 3X_L600_cell, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [4]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "6720 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'cell' (cell), and shuffling 6720 examples.\n",
      "Generating dataset with 6720 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 819 in position 6719))\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 51\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_cell/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_cell_cell_2018-12-06-18-05.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.885418713092804.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7275847792625427.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7987796664237976.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'cell' (cell)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.885418713092804.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7275847792625427.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7987796664237976.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_cell -m 3X_L600_cell_cell_2018-12-06-18-05.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tissue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='tissue']\" \\\n",
    "-f 3X_L600_tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_tissue \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_tissue_tissue_2018-12-06-23-58.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_tissue_tissue_2018-12-06-23-58.zip rack/tissue.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_tissue_tissue_2018-12-06-23-58.zip, testset: 3X_L600_tissue, tokenization: False\n",
      "opt from model namebase=3X_L600_tissue; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['tissue']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [5]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "3465 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'tissue' (tissue), and shuffling 3465 examples.\n",
      "Generating dataset with 3465 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 3007 in position 3464)\n",
      "done\n",
      "\n",
      "0.000 0.022 1.000 0.043\n",
      "0.100 0.543 0.820 0.653\n",
      "0.200 0.652 0.774 0.707\n",
      "0.300 0.713 0.734 0.723\n",
      "0.400 0.756 0.699 0.726\n",
      "0.500 0.793 0.663 0.722\n",
      "0.600 0.825 0.623 0.710\n",
      "0.700 0.856 0.570 0.684\n",
      "0.800 0.883 0.482 0.624\n",
      "0.900 0.917 0.348 0.504\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_tissue -m 3X_L600_tissue_tissue_2018-12-06-23-58.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_tissue_tissue_2018-12-06-23-58.zip, testset: 3X_L600_tissue, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [5]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "2862 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'tissue' (tissue), and shuffling 2862 examples.\n",
      "Generating dataset with 2862 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 420 in position 2861))\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 21\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_tissue/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_tissue_tissue_2018-12-06-23-58.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.6922190189361572.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6344426870346069.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.6620727777481079.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'tissue' (tissue)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.6922190189361572.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6344426870346069.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.6620727777481079.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_tissue -m 3X_L600_tissue_tissue_2018-12-06-23-58.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organism "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@type='organism']\" \\\n",
    "-f 3X_L600_organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_organism \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o organism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_organism_organism_2018-12-07-04-36.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_organism_organism_2018-12-07-04-36.zip rack/organism.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_organism_organism_2018-12-07-04-36.zip, testset: 3X_L600_organism, tokenization: False\n",
      "opt from model namebase=3X_L600_organism; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['organism']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [6]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "5019 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'organism' (organism), and shuffling 5019 examples.\n",
      "Generating dataset with 5019 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 1060 in position 5018)\n",
      "done\n",
      "\n",
      "0.000 0.017 1.000 0.033\n",
      "0.100 0.649 0.822 0.725\n",
      "0.200 0.744 0.797 0.770\n",
      "0.300 0.793 0.781 0.787\n",
      "0.400 0.827 0.769 0.797\n",
      "0.500 0.854 0.757 0.802\n",
      "0.600 0.878 0.743 0.805\n",
      "0.700 0.899 0.725 0.803\n",
      "0.800 0.921 0.698 0.794\n",
      "0.900 0.946 0.646 0.768\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_organism -m 3X_L600_organism_organism_2018-12-07-04-36.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_organism_organism_2018-12-07-04-36.zip, testset: 3X_L600_organism, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [6]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "4059 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'organism' (organism), and shuffling 4059 examples.\n",
      "Generating dataset with 4059 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 1341 in position 4058)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 30\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_organism/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_organism_organism_2018-12-07-04-36.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8647826313972473.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8022317886352539.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8323336839675903.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'organism' (organism)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8647826313972473.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8022317886352539.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8323336839675903.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_organism -m 3X_L600_organism_organism_2018-12-07-04-36.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -L1200 -X5 -b -c NCBI_disease -f 5X_L1200_NCBI_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -E120 -Z128 -R0.01 -o disease -f 5X_L1200_NCBI_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `5X_L1200_NCBI_disease_disease_2018-12-12-07-44.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip rack/disease.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip, testset: 5X_L1200_NCBI_disease, tokenization: False\n",
      "opt from model namebase=5X_L1200_NCBI_disease; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['disease']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [18]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "395 text examples of size 1240\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features disease: 'disease' (), and shuffling 395 examples.\n",
      "Generating dataset with 395 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 146 in position 394)\n",
      "done\n",
      "\n",
      "0.000 0.079 1.000 0.146\n",
      "0.100 0.757 0.856 0.803\n",
      "0.200 0.838 0.812 0.825\n",
      "0.300 0.886 0.776 0.827\n",
      "0.400 0.915 0.745 0.821\n",
      "0.500 0.934 0.713 0.809\n",
      "0.600 0.951 0.680 0.793\n",
      "0.700 0.964 0.641 0.770\n",
      "0.800 0.976 0.593 0.738\n",
      "0.900 0.986 0.517 0.678\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 5X_L1200_NCBI_disease -m 5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip, testset: 5X_L1200_NCBI_disease, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [18]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "1190 text examples of size 1240\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features disease: 'disease' (), and shuffling 1190 examples.\n",
      "Generating dataset with 1190 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 533 in position 1189)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 8\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/5X_L1200_NCBI_disease/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8373895287513733.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7577043771743774.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7955565452575684.2f\n",
      "\n",
      " Feature: '\u001b[1mdisease: 'disease' ()\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8373895287513733.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7577043771743774.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7955565452575684.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 5X_L1200_NCBI_disease -m 5X_L1200_NCBI_disease_disease_2018-12-12-07-44.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental assay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 -y \".//sd-tag[@category='assay']\" \\\n",
    "-f 3X_L600_assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_assay \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o assay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_assay_assay_2018-12-06-06-59.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_assay_assay_2018-12-06-06-59.zip rack/exp_assay.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_assay_assay_2018-12-06-06-59.zip, testset: 3X_L600_assay, tokenization: False\n",
      "opt from model namebase=3X_L600_assay; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['assay']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [14]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "11295 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features assay: 'assay' (), and shuffling 11295 examples.\n",
      "Generating dataset with 11295 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 9885 in position 11294))\n",
      "done\n",
      "\n",
      "0.000 0.030 1.000 0.059\n",
      "0.100 0.520 0.879 0.653\n",
      "0.200 0.639 0.838 0.725\n",
      "0.300 0.710 0.808 0.756\n",
      "0.400 0.762 0.782 0.772\n",
      "0.500 0.804 0.755 0.779\n",
      "0.600 0.840 0.728 0.780\n",
      "0.700 0.872 0.696 0.774\n",
      "0.800 0.901 0.654 0.758\n",
      "0.900 0.935 0.587 0.721\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_assay -m 3X_L600_assay_assay_2018-12-06-06-59.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_assay_assay_2018-12-06-06-59.zip, testset: 3X_L600_assay, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [14]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "9510 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features assay: 'assay' (), and shuffling 9510 examples.\n",
      "Generating dataset with 9510 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 3663 in position 9509)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 73\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_assay/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_assay_assay_2018-12-06-06-59.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8506407737731934.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6867772340774536.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7599764466285706.2f\n",
      "\n",
      " Feature: '\u001b[1massay: 'assay' ()\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.8506407737731934.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6867772340774536.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7599764466285706.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_assay -m 3X_L600_assay_assay_2018-12-06-06-59.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention-assay geneprod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 \\\n",
    "-y \".//sd-tag[@type='gene']\",\".//sd-tag[@type='protein']\" \\\n",
    "-e \".//sd-tag[@type='gene']\",\".//sd-tag[@type='protein']\" \\\n",
    "-A \".//sd-tag[@role='intervention']\",\\\n",
    "\".//sd-tag[@role='assayed']\",\\\n",
    "\".//sd-tag[@role='normalizing']\",\\\n",
    "\".//sd-tag[@role='experiment']\",\\\n",
    "\".//sd-tag[@role='component']\", \\\n",
    "-f 3X_L600_geneprod_anonym_not_reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_geneprod_anonym_not_reporter \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o intervention,assayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.sddl` (size: 100481)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip rack/role_geneprod.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip, testset: 3X_L600_geneprod_anonym_not_reporter, tokenization: False\n",
      "opt from model namebase=3X_L600_geneprod_anonym_not_reporter; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['intervention', 'assayed']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=2\n",
      "nf.output= 2\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [8, 9]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "13977 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'intervention' (intervention), entity: 'assayed' (assayed), and shuffling 13977 examples.\n",
      "Generating dataset with 13977 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 4800 in position 13976))\n",
      "done\n",
      "\n",
      "0.000\t0.000 0.010; 0.014 1.000; 1.000 0.020; 0.028\n",
      "0.100\t0.100 0.520; 0.640 0.936; 0.965 0.669; 0.769\n",
      "0.200\t0.200 0.590; 0.707 0.881; 0.917 0.707; 0.798\n",
      "0.300\t0.300 0.639; 0.746 0.834; 0.877 0.724; 0.806\n",
      "0.400\t0.400 0.680; 0.777 0.787; 0.838 0.729; 0.806\n",
      "0.500\t0.500 0.718; 0.802 0.732; 0.792 0.725; 0.797\n",
      "0.600\t0.600 0.752; 0.825 0.666; 0.739 0.706; 0.780\n",
      "0.700\t0.700 0.793; 0.848 0.580; 0.667 0.670; 0.747\n",
      "0.800\t0.800 0.841; 0.875 0.455; 0.559 0.590; 0.682\n",
      "0.900\t0.900 0.894; 0.913 0.235; 0.337 0.373; 0.493\n",
      "1.000\t1.000 0.500; 0.500 0.000; 0.000 0.000; 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod_anonym_not_reporter -m 3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip, testset: 3X_L600_geneprod_anonym_not_reporter, tokenization: True\n",
      "nf.output= 2\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [8, 9]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "12249 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'intervention' (intervention), entity: 'assayed' (assayed), and shuffling 12249 examples.\n",
      "Generating dataset with 12249 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 3211 in position 12248))\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 94\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_geneprod_anonym_not_reporter/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7413406372070312.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7881475687026978.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7639768123626709.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'intervention' (intervention)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7023831009864807.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.7338533401489258.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7177734971046448.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'assayed' (assayed)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7802982330322266.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8424418568611145.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8101801872253418.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod_anonym_not_reporter -m 3X_L600_geneprod_anonym_not_reporter_intervention_assayed_2018-12-10-00-33.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geneprod Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 \\\n",
    "-y \".//sd-tag[@type='gene']\",\".//sd-tag[@type='protein']\" \\\n",
    "-e \".//sd-tag[@type='gene']\",\".//sd-tag[@type='protein']\" \\\n",
    "-f 3X_L600_geneprod_reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_geneprod_reporter \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o reporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.sddl` (size: 100279)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip rack/reporter_geneprod.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip, testset: 3X_L600_geneprod_reporter, tokenization: False\n",
      "opt from model namebase=3X_L600_geneprod_reporter; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['reporter']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [11]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "13977 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'reporter' (reporter), and shuffling 13977 examples.\n",
      "Generating dataset with 13977 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 1910 in position 13976))\n",
      "done\n",
      "\n",
      "0.000 0.004 1.000 0.008\n",
      "0.100 0.722 0.924 0.811\n",
      "0.200 0.776 0.913 0.839\n",
      "0.300 0.806 0.904 0.852\n",
      "0.400 0.832 0.895 0.862\n",
      "0.500 0.856 0.886 0.870\n",
      "0.600 0.880 0.872 0.876\n",
      "0.700 0.903 0.851 0.876\n",
      "0.800 0.930 0.820 0.871\n",
      "0.900 0.959 0.756 0.845\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod_reporter -m 3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip, testset: 3X_L600_geneprod_reporter, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [11]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "12249 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'reporter' (reporter), and shuffling 12249 examples.\n",
      "Generating dataset with 12249 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 9551 in position 12248))\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 94\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_geneprod_reporter/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.942307710647583.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8355816006660461.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8857412934303284.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'reporter' (reporter)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.942307710647583.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.8355816006660461.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.8857412934303284.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_geneprod_reporter -m 3X_L600_geneprod_reporter_reporter_2018-12-08-04-24.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention-assay small molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 \\\n",
    "-y \".//sd-tag[@type='molecule']\" \\\n",
    "-e \".//sd-tag[@type='molecule']\" \\\n",
    "-A \".//sd-tag[@type='molecule']\" \\\n",
    "-f 3X_L600_molecule_anonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_molecule_anonym \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o intervention,assayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.sddl` (size: 100315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip rack/role_small_molecule.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip, testset: 3X_L600_molecule_anonym, tokenization: False\n",
      "opt from model namebase=3X_L600_molecule_anonym; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['intervention', 'assayed']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=2\n",
      "nf.output= 2\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [8, 9]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "5919 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'intervention' (intervention), entity: 'assayed' (assayed), and shuffling 5919 examples.\n",
      "Generating dataset with 5919 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 1130 in position 5918)\n",
      "done\n",
      "\n",
      "0.000\t0.000 0.014; 0.003 1.000; 1.000 0.027; 0.006\n",
      "0.100\t0.100 0.697; 0.519 0.974; 0.766 0.813; 0.619\n",
      "0.200\t0.200 0.730; 0.584 0.949; 0.679 0.825; 0.628\n",
      "0.300\t0.300 0.755; 0.625 0.923; 0.619 0.830; 0.622\n",
      "0.400\t0.400 0.778; 0.658 0.892; 0.562 0.831; 0.607\n",
      "0.500\t0.500 0.803; 0.690 0.851; 0.503 0.826; 0.582\n",
      "0.600\t0.600 0.832; 0.717 0.805; 0.435 0.818; 0.541\n",
      "0.700\t0.700 0.860; 0.763 0.740; 0.373 0.795; 0.501\n",
      "0.800\t0.800 0.894; 0.836 0.644; 0.302 0.749; 0.444\n",
      "0.900\t0.900 0.932; 0.914 0.477; 0.186 0.631; 0.309\n",
      "1.000\t1.000 0.500; 0.500 0.000; 0.000 0.000; 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_molecule_anonym -m 3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip, testset: 3X_L600_molecule_anonym, tokenization: True\n",
      "nf.output= 2\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [8, 9]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "5118 text examples of size 640\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features entity: 'intervention' (intervention), entity: 'assayed' (assayed), and shuffling 5118 examples.\n",
      "Generating dataset with 5118 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 738 in position 5117))\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 38\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/3X_L600_molecule_anonym/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.6353134512901306.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.6647820472717285.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.6447984576225281.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'intervention' (intervention)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.7124301791191101.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.858609676361084.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.7787191867828369.2f\n",
      "\n",
      " Feature: '\u001b[1mentity: 'assayed' (assayed)\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.5581967234611511.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.47095435857772827.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.5108777284622192.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 3X_L600_molecule_anonym -m 3X_L600_molecule_anonym_intervention_assayed_2018-12-13-05-20.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "--noocr -E \".//figure-caption\" \\\n",
    "-L1200 -X5 -f 5X_L1200_figure_level_no_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 5X_L1200_figure_level_no_ocr \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o panel_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved `5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.sddl` (size: 100167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp models/5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip rack/panel_start.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip, testset: 5X_L1200_figure_level_no_ocr, tokenization: False\n",
      "opt from model namebase=5X_L1200_figure_level_no_ocr; modelname=; learning_rate=0.01; dropout=0.1; epochs=120; minibatch_size=128; selected_features=['panel_start']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; use_ocr_context=; use_viz_context=False; nf_input=32; nf_output=1\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [19]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "6800 text examples of size 1240\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features : 'panel_start' (), and shuffling 6800 examples.\n",
      "Generating dataset with 6800 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 5708 in position 6799)\n",
      "done\n",
      "\n",
      "0.000 0.002 1.000 0.005\n",
      "0.100 0.648 0.968 0.777\n",
      "0.200 0.719 0.958 0.821\n",
      "0.300 0.760 0.950 0.844\n",
      "0.400 0.790 0.941 0.859\n",
      "0.500 0.815 0.931 0.869\n",
      "0.600 0.839 0.916 0.875\n",
      "0.700 0.862 0.895 0.878\n",
      "0.800 0.889 0.859 0.874\n",
      "0.900 0.927 0.769 0.841\n",
      "1.000 0.500 0.000 0.000\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 5X_L1200_figure_level_no_ocr -m 5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip -S -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip, testset: 5X_L1200_figure_level_no_ocr, tokenization: True\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [19]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading features.pyth as features for the dataset.\n",
      "Loading textcoded.pyth as encoded text for the dataset.\n",
      "Loading ocrcontext.pyth as image-based OCR data.\n",
      "No image-based visual context data available.\n",
      "Loading text.txt for the original texts of the dataset.\n",
      "Loading provenance.txt as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "6255 text examples of size 1240\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features : 'panel_start' (), and shuffling 6255 examples.\n",
      "Generating dataset with 6255 examples\n",
      "[████████████████████████████████████████████████████████████] 100% ...loading example 3973 in position 6254)\n",
      "done\n",
      "\n",
      "[████████████████████████████████████████████████████████████] 100% ...tokenizing minibatch 47\n",
      "\n",
      "\u001b[31;1m========================================================\u001b[0m\n",
      "\n",
      "\u001b[31;1m Data: ./data4th/5X_L1200_figure_level_no_ocr/test\u001b[0m\n",
      "\n",
      "\u001b[31;1m Model: 5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip\u001b[0m\n",
      "\n",
      " Global stats: \u001b[1m\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.870161235332489.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.9474058151245117.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.9071421027183533.2f\n",
      "\n",
      " Feature: '\u001b[1m: 'panel_start' ()\u001b[0m'\n",
      "\n",
      "\t\u001b[32;1mprecision\u001b[0m = 0.870161235332489.2f\n",
      "\t\u001b[33;1mrecall\u001b[0m = 0.9474058151245117.2f\n",
      "\t\u001b[36;1mf1\u001b[0m = 0.9071421027183533.2f\n"
     ]
    }
   ],
   "source": [
    "smtag-eval -f 5X_L1200_figure_level_no_ocr -m 5X_L1200_figure_level_no_ocr_panel_start_2018-12-12-00-25.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special models (experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pan entity measured variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "-L600 -X3 \\\n",
    "-A \".//sd-tag[@role]\" \\\n",
    "-f 3X_L600_all_entities_role_anonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -f 3X_L600_all_entities_role_anonym \\\n",
    "-E120 -Z128 -R0.01 \\\n",
    "-o intervention,assayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-figure level intervention-assayed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-convert2th -c 181203all \\\n",
    "--noocr -E \".\" \\\n",
    "-L5000 -X1 -f 1X_L5000_doc_level_no_ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rack for SmartTag engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell.zip\t\torganism.zip\t\trole_small_molecule.zip\n",
      "disease.zip\t\tpanel_start.zip\t\tsmall_molecule.zip\n",
      "exp_assay.zip\t\treporter_geneprod.zip\tsubcellular.zip\n",
      "geneprod.zip\t\trole_geneprod.zip\ttissue.zip\n"
     ]
    }
   ],
   "source": [
    "ls rack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtag-meta -E50 -o panel_start -H depth,kernel -I 25 -f 5X_L1200_entities -w /efs/smtag # after data transfer to GPU machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning combo:\n",
    "    4,4,4,4\n",
    "    \n",
    "But a lot of variability. Initialization issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smtag-meta -E50 -o geneprod -H kernel,depth -I 25 -f 5X_L1200_gene_protein -w /efs/smtag # after transfer to GPU machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning combo with `f1=0.80` after 50 epochs, no overfitting with valid:\n",
    "\n",
    "    namebase=5X_L1200_gene_protein; modelname=; learning_rate=0.01000000000000001; epochs=50; minibatch_size=32; selected_features=['geneprod']; collapsed_features=[]; overlap_features=[]; features_as_input=[]; nf_table=[8, 8, 8]; pool_table=[2, 2, 2]; kernel_table=[6, 6, 6]; dropout=0.1; validation_fraction=0.2; nf_input=32; nf_output=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
