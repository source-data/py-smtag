{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the SmartTag models\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(.venv) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Neo4j.\n",
      "Started neo4j (pid 59966). It is available at http://localhost:7474/\n",
      "There may be a short delay until the server is ready.\n",
      "See /Users/lemberger/Documents/code/neo4j/logs/neo4j.log for current status.\n"
     ]
    }
   ],
   "source": [
    "neo4j start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j is running at pid 59966\n"
     ]
    }
   ],
   "source": [
    "neo4j status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1X_L1200_disease_w_test.zip\n",
      "1X_L1200_disease_w_train.zip\n",
      "1X_L1200_ncbi_disease_w_test.zip\n",
      "1X_L1200_ncbi_disease_w_train.prov\n",
      "1X_L1200_ncbi_disease_w_train.pyth\n",
      "1X_L1200_ncbi_disease_w_train.txt\n",
      "1X_L1200_ncbi_disease_w_train.zip\n",
      "1X_L1200_ncbi_disease_w_train_textcoded.pyth\n",
      "5X_L1200_ncbi_disease_w_test.prov\n",
      "5X_L1200_ncbi_disease_w_test.pyth\n",
      "5X_L1200_ncbi_disease_w_test.txt\n",
      "5X_L1200_ncbi_disease_w_test.zip\n",
      "5X_L1200_ncbi_disease_w_test_textcoded.pyth\n",
      "5X_L1200_ncbi_disease_w_train.prov\n",
      "5X_L1200_ncbi_disease_w_train.pyth\n",
      "5X_L1200_ncbi_disease_w_train.txt\n",
      "5X_L1200_ncbi_disease_w_train.zip\n",
      "5X_L1200_ncbi_disease_w_train_textcoded.pyth\n",
      "5X_L1200_small_molecule_w_test.zip\n",
      "5X_L1200_small_molecule_w_train.zip\n",
      "CALBC_SSC_DISO\n",
      "NCBI_disease\n",
      "test_brat\n",
      "test_entities_test.zip\n",
      "test_entities_train.prov\n",
      "test_entities_train.pyth\n",
      "test_entities_train.txt\n",
      "test_entities_train.zip\n",
      "test_entities_train_textcoded.pyth\n",
      "testing_brat_test.zip\n",
      "testing_brat_train.prov\n",
      "testing_brat_train.pyth\n",
      "testing_brat_train.txt\n",
      "testing_brat_train.zip\n",
      "testing_brat_train_textcoded.pyth\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: models: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sdgraph2th.py [-h] [-f FILENAMEBASE] [-X ITERATIONS] [-v] [-L LENGTH]\n",
      "                     [-t TESTFRACT] [-W] [-S] [-d] [-p PADDING]\n",
      "                     [-A TAGS2ANONYMIZE] [-AA DONOTANONYMIZE] [-l LIMIT]\n",
      "                     [-Y YEAR_RANGE] [-J JOURNALS] [-D DOI] [-y TYPE] [-e]\n",
      "                     [-s] [-r ROLE] [-N] [-w WORKING_DIRECTORY]\n",
      "\n",
      "Generates text and tensor files from tagged text in sd-graph.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FILENAMEBASE, --filenamebase FILENAMEBASE\n",
      "                        namebase to save trainset and features set files\n",
      "  -X ITERATIONS, --iterations ITERATIONS\n",
      "                        number of times each example is sampled\n",
      "  -v, --verbose         verbosity\n",
      "  -L LENGTH, --length LENGTH\n",
      "                        length of the text snippets used as example\n",
      "  -t TESTFRACT, --testfract TESTFRACT\n",
      "                        fraction of papers in testset\n",
      "  -W, --window          switches to the sampling fig legends using a random\n",
      "                        window instead of parsing full sentences\n",
      "  -S, --start           switches to mode where fig legends are simply taken\n",
      "                        from the start of the text and truncated appropriately\n",
      "  -d, --disable_shifting\n",
      "                        disable left random padding which is used by default\n",
      "                        to shift randomly text\n",
      "  -p PADDING, --padding PADDING\n",
      "                        minimum padding added to text\n",
      "  -A TAGS2ANONYMIZE, --tags2anonymize TAGS2ANONYMIZE\n",
      "                        tag type to anonymise\n",
      "  -AA DONOTANONYMIZE, --donotanonymize DONOTANONYMIZE\n",
      "                        role of tags that should NOT be anonymized\n",
      "  -l LIMIT, --limit LIMIT\n",
      "                        limit number of papers scanned, mainly for testing\n",
      "  -Y YEAR_RANGE, --year_range YEAR_RANGE\n",
      "                        select papers published in the start:end year range\n",
      "  -J JOURNALS, --journals JOURNALS\n",
      "                        select set of journals, comma delimited\n",
      "  -D DOI, --doi DOI     restrict to a single doi\n",
      "  -y TYPE, --type TYPE  makes sure each example has entities of the specified\n",
      "                        type\n",
      "  -e, --exclusive       only the tags selected by -y are kept, the others are\n",
      "                        removed\n",
      "  -s, --selective       keep the roles only for the entities selected by the\n",
      "                        -y option\n",
      "  -r ROLE, --role ROLE  makes sure each example has entities with the\n",
      "                        specified role\n",
      "  -N, --not_safe_mode   protects against some misformed XML in caption; set\n",
      "                        this option to False for debugging\n",
      "  -w WORKING_DIRECTORY, --working_directory WORKING_DIRECTORY\n",
      "                        Specify the working directory where to read and write\n",
      "                        files to\n",
      "(.venv) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "python -m smtag.datagen.sdgraph2th --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: meta.py [-h] [-f FILE] [-E EPOCHS] [-Z MINIBATCH_SIZE]\n",
      "               [-R LEARNING_RATE] [-V VALIDATION_FRACTION]\n",
      "               [-o OUTPUT_FEATURES] [-i FEATURES_AS_INPUT]\n",
      "               [-a OVERLAP_FEATURES] [-c COLLAPSED_FEATURES] [-n NF_TABLE]\n",
      "               [-k KERNEL_TABLE] [-p POOL_TABLE] [-w WORKING_DIRECTORY]\n",
      "\n",
      "Top level module to manage training.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FILE, --file FILE  Namebase of dataset to import (default:\n",
      "                        test_entities_train)\n",
      "  -E EPOCHS, --epochs EPOCHS\n",
      "                        Number of training epochs. (default: 120)\n",
      "  -Z MINIBATCH_SIZE, --minibatch_size MINIBATCH_SIZE\n",
      "                        Minibatch size. (default: 128)\n",
      "  -R LEARNING_RATE, --learning_rate LEARNING_RATE\n",
      "                        Learning rate. (default: 0.001)\n",
      "  -V VALIDATION_FRACTION, --validation_fraction VALIDATION_FRACTION\n",
      "                        Fraction of the dataset that should be used as\n",
      "                        validation set during training. (default: 0.2)\n",
      "  -o OUTPUT_FEATURES, --output_features OUTPUT_FEATURES\n",
      "                        Selected output features (use quotes if comma+space\n",
      "                        delimited). (default: geneprod)\n",
      "  -i FEATURES_AS_INPUT, --features_as_input FEATURES_AS_INPUT\n",
      "                        Features that should be added to the input (use quotes\n",
      "                        if comma+space delimited). (default: )\n",
      "  -a OVERLAP_FEATURES, --overlap_features OVERLAP_FEATURES\n",
      "                        Features that should be combined by intersecting them\n",
      "                        (equivalent to AND operation) (use quotes if\n",
      "                        comma+space delimited). (default: )\n",
      "  -c COLLAPSED_FEATURES, --collapsed_features COLLAPSED_FEATURES\n",
      "                        Features that should be collapsed into a single one\n",
      "                        (equivalent to OR operation) (use quotes if\n",
      "                        comma+space delimited). (default: )\n",
      "  -n NF_TABLE, --nf_table NF_TABLE\n",
      "                        Number of features in each hidden super-layer.\n",
      "                        (default: 8,8,8)\n",
      "  -k KERNEL_TABLE, --kernel_table KERNEL_TABLE\n",
      "                        Convolution kernel for each hidden layer. (default:\n",
      "                        6,6,6)\n",
      "  -p POOL_TABLE, --pool_table POOL_TABLE\n",
      "                        Pooling for each hidden layer (use quotes if\n",
      "                        comma+space delimited). (default: 2,2,2)\n",
      "  -w WORKING_DIRECTORY, --working_directory WORKING_DIRECTORY\n",
      "                        Specify the working directory for meta, where to read\n",
      "                        and write files to (default: None)\n",
      "(.venv) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "python -m smtag.train.meta --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt[namebase]=test_entities_train\n",
      "opt[learning_rate]=0.001\n",
      "opt[epochs]=1\n",
      "opt[minibatch_size]=2\n",
      "opt[selected_features]=['geneprod']\n",
      "opt[collapsed_features]=[]\n",
      "opt[overlap_features]=[]\n",
      "opt[features_as_input]=[]\n",
      "opt[nf_table]=[8, 8, 8]\n",
      "opt[pool_table]=[2, 2, 2]\n",
      "opt[kernel_table]=[6, 6, 6]\n",
      "opt[dropout]=0.1\n",
      "opt[validation_fraction]=0.2\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [21]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading ./data/test_entities_train.pyth as features for the dataset.\n",
      "Loading ./data/test_entities_train_textcoded.pyth as encoded text for the dataset.\n",
      "Loading ./data/test_entities_train.txt for the original texts of the dataset.\n",
      "Loading ./data/test_entities_train.prov as provenance info for the examples in the dataset.\n",
      "Dataset dimensions:\n",
      "100 text examples of size 160\n",
      "0 input features (in-channels).\n",
      "22 output features (out-channels).\n",
      "Creating dataset with selected features [<smtag.common.mapper.Entity object at 0x105c41320>], and shuffling 100 examples.\n",
      "normal trainset and validation set mode\n",
      "Generating train set with 80 examples (0, 80)\n",
      "input dataset['train'] tensor created\n",
      "output dataset['train'] tensor created\n",
      "[############################################################] 100% ...loading 80 examples (0 to 80) into dataset['train'] (example_i=79,index=79)\n",
      "done\n",
      "\n",
      "Generating valid set with 20 examples (80, 100)\n",
      "input dataset['valid'] tensor created\n",
      "output dataset['valid'] tensor created\n",
      "[############################################################] 100% ...loading 20 examples (80 to 100) into dataset['valid'] (example_i=99,index=19)\n",
      "done\n",
      "\n",
      "input, output sizes: torch.Size([2, 1, 160]), torch.Size([2, 1, 160])\n",
      "namebase=test_entities_train\n",
      "learning_rate=0.001\n",
      "epochs=1\n",
      "minibatch_size=2\n",
      "selected_features=['geneprod']\n",
      "collapsed_features=[]\n",
      "overlap_features=[]\n",
      "features_as_input=[]\n",
      "nf_table=[8, 8, 8]\n",
      "pool_table=[2, 2, 2]\n",
      "kernel_table=[6, 6, 6]\n",
      "dropout=0.1\n",
      "validation_fraction=0.2\n",
      "nf_input=32\n",
      "nf_output=1\n",
      "[############################################################] 100% ...tokenizing minibatch 9\n",
      "Expected:\n",
      "\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1m窶申u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1mg\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1mg\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m(\u001b[0m\u001b[30;1mN\u001b[0m\u001b[30;1mT\u001b[0m\u001b[30;1m)\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1m窶申u001b[0m\u001b[34;1mJ\u001b[0m\u001b[34;1mA\u001b[0m\u001b[34;1mK\u001b[0m\u001b[34;1m2\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1ms\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mR\u001b[0m\u001b[30;1mN\u001b[0m\u001b[30;1mA\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1my\u001b[0m\u001b[30;1mz\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1md\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mb\u001b[0m\u001b[30;1my\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mw\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1ms\u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mb\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1m.\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mC\u001b[0m\u001b[30;1m)\u001b[0m\u001b[30;1mC\u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1mf\u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mc\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mv\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mc\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m(\u001b[0m\u001b[30;1mu\u001b[0m\u001b[30;1mp\u001b[0m\u001b[30;1mp\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mp\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1m)\u001b[0m\u001b[30;1m,\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mf\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mx\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1md\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mc\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1ms\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m(\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1mo\u001b[0m\u001b[30;1mw\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1mr\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1mf\u001b[0m\u001b[30;1mt\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mp\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1me\u001b[0m\u001b[30;1ml\u001b[0m\u001b[30;1m)\u001b[0m\u001b[30;1m,\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mm\u001b[0m\u001b[30;1ma\u001b[0m\u001b[30;1mg\u001b[0m\u001b[30;1mi\u001b[0m\u001b[30;1mn\u001b[0m\u001b[30;1mg\u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\u001b[30;1m \u001b[0m\n",
      "Tagging track 0\n",
      "_________________________________________||||___________________________________________________________________________________________________________________\n",
      "\n",
      "Predicted:\n",
      "\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1m窶申u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1mg\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1mg\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m(\u001b[0m\u001b[34;1mN\u001b[0m\u001b[34;1mT\u001b[0m\u001b[34;1m)\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1m窶申u001b[0m\u001b[34;1mJ\u001b[0m\u001b[34;1mA\u001b[0m\u001b[34;1mK\u001b[0m\u001b[34;1m2\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1ms\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mR\u001b[0m\u001b[34;1mN\u001b[0m\u001b[34;1mA\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1my\u001b[0m\u001b[34;1mz\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1md\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mb\u001b[0m\u001b[34;1my\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mw\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1ms\u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mb\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1m.\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mC\u001b[0m\u001b[34;1m)\u001b[0m\u001b[34;1mC\u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1mf\u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mc\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mv\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mc\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m(\u001b[0m\u001b[34;1mu\u001b[0m\u001b[34;1mp\u001b[0m\u001b[34;1mp\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mp\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1m)\u001b[0m\u001b[34;1m,\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mf\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mx\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1md\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mc\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1ms\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m(\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1mo\u001b[0m\u001b[34;1mw\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1mr\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1mf\u001b[0m\u001b[34;1mt\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mp\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1me\u001b[0m\u001b[34;1ml\u001b[0m\u001b[34;1m)\u001b[0m\u001b[34;1m,\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mm\u001b[0m\u001b[34;1ma\u001b[0m\u001b[34;1mg\u001b[0m\u001b[34;1mi\u001b[0m\u001b[34;1mn\u001b[0m\u001b[34;1mg\u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\u001b[34;1m \u001b[0m\n",
      "Tagging track 0\n",
      ":::::::::::::::::::::::::::::^^:::::::::^^|^^:::^^^::::::::::::::::::::::::::::^::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "epoch #0 losses: train=0.66575, valid=0.62366\n",
      "\n",
      "epoch #0 f1: entity: 'geneprod' (geneprod)=0.31765\n",
      "saved test_entities_train_geneprod_2018-09-13-18-11.sddl (size: 100423)\n",
      "saved test_entities_train_geneprod_2018-09-13-18-11.json (size: 354)\n"
     ]
    }
   ],
   "source": [
    "python -m smtag.train.meta -Z2 -E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 59789\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir runs &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59821 ttys002    0:00.00 grep tensoboard\n"
     ]
    }
   ],
   "source": [
    "ps -a | grep tensoboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small molecules\n",
    "\n",
    "Generate the data with `-5X` sampling of each example of length `-L1200` characters with a random window method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_clause  LIMIT 20 \n",
      "entity_type_clause AND ( t.type = 'molecule') \n",
      "tags2anonmymize_clause \n",
      "donotanonymize_clause \n",
      "b'0 panels found for figure Figure 1 (1) in paper 10.1289/ehp.84589'\n",
      "b'2 panels found for figure Figure 2 (53) in paper 10.1289/ehp.84589'\n",
      "b'4 panels found for figure Figure 3 (89) in paper 10.1289/ehp.84589'\n",
      "b'0 panels found for figure Figure 4 (127) in paper 10.1289/ehp.84589'\n",
      "b'3 panels found for figure Figure 5 (154) in paper 10.1289/ehp.84589'\n",
      "b'0 panels found for figure Figure 6 (178) in paper 10.1289/ehp.84589'\n",
      "number of figures in  0 10.1289/ehp.84589 3\n",
      "counted 9 panels.\n",
      "b'0 panels found for figure Figure 1 (194) in paper 10.1002/eji.200323730'\n",
      "b'1 panels found for figure Figure 2 (238) in paper 10.1002/eji.200323730'\n",
      "b'2 panels found for figure Figure 3 (272) in paper 10.1002/eji.200323730'\n",
      "b'2 panels found for figure Figure 4 (300) in paper 10.1002/eji.200323730'\n",
      "b'4 panels found for figure Figure 5 (352) in paper 10.1002/eji.200323730'\n",
      "b'2 panels found for figure Figure 6 (393) in paper 10.1002/eji.200323730'\n",
      "number of figures in  193 10.1002/eji.200323730 5\n",
      "counted 20 panels.\n",
      "b'0 panels found for figure Figure 1 (436) in paper 10.1002/eji.200737900'\n",
      "b'2 panels found for figure Figure 2 (469) in paper 10.1002/eji.200737900'\n",
      "b'2 panels found for figure Figure 3 (521) in paper 10.1002/eji.200737900'\n",
      "number of figures in  435 10.1002/eji.200737900 2\n",
      "counted 24 panels.\n",
      "b'5 panels found for figure Figure 1 (545) in paper 10.1002/eji.200940025'\n",
      "b'1 panels found for figure Figure 2 (618) in paper 10.1002/eji.200940025'\n",
      "b'5 panels found for figure Figure 3 (645) in paper 10.1002/eji.200940025'\n",
      "b'0 panels found for figure Figure 4 (705) in paper 10.1002/eji.200940025'\n",
      "b'4 panels found for figure Figure 5 (721) in paper 10.1002/eji.200940025'\n",
      "b'0 panels found for figure Figure 6 (778) in paper 10.1002/eji.200940025'\n",
      "b'6 panels found for figure Figure 7 (790) in paper 10.1002/eji.200940025'\n",
      "number of figures in  544 10.1002/eji.200940025 5\n",
      "counted 45 panels.\n",
      "b'7 panels found for figure Figure 1 (861) in paper 10.1002/embr.201337995'\n",
      "b'4 panels found for figure Figure 2 (961) in paper 10.1002/embr.201337995'\n",
      "b'3 panels found for figure Figure 3 (1033) in paper 10.1002/embr.201337995'\n",
      "b'1 panels found for figure Figure 4 (1094) in paper 10.1002/embr.201337995'\n",
      "b'3 panels found for figure Figure 5 (1137) in paper 10.1002/embr.201337995'\n",
      "number of figures in  860 10.1002/embr.201337995 5\n",
      "counted 63 panels.\n",
      "b'1 panels found for figure Figure 1 (1203) in paper 10.1002/embr.201338003'\n",
      "b'2 panels found for figure Figure 2 (1249) in paper 10.1002/embr.201338003'\n",
      "b'1 panels found for figure Figure 3 (1289) in paper 10.1002/embr.201338003'\n",
      "b'3 panels found for figure Figure 4 (1341) in paper 10.1002/embr.201338003'\n",
      "number of figures in  1202 10.1002/embr.201338003 4\n",
      "counted 70 panels.\n",
      "b'1 panels found for figure Figure 1 (1400) in paper 10.1038/hdy.2015.103'\n",
      "b'2 panels found for figure Figure 2 (1429) in paper 10.1038/hdy.2015.103'\n",
      "b'3 panels found for figure Figure 3 (1452) in paper 10.1038/hdy.2015.103'\n",
      "b'1 panels found for figure Figure 4 (1476) in paper 10.1038/hdy.2015.103'\n",
      "b'1 panels found for figure Figure 5 (1495) in paper 10.1038/hdy.2015.103'\n",
      "b'1 panels found for figure Figure 6 (1548) in paper 10.1038/hdy.2015.103'\n",
      "number of figures in  1399 10.1038/hdy.2015.103 6\n",
      "counted 79 panels.\n",
      "b'0 panels found for figure Figure 1 (1568) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 2 (1628) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 3 (1684) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 4 (1710) in paper 10.1111/tra.12151'\n",
      "b'2 panels found for figure Figure 5 (1737) in paper 10.1111/tra.12151'\n",
      "b'2 panels found for figure Figure 6 (1773) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 7 (1798) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 8 (1820) in paper 10.1111/tra.12151'\n",
      "b'0 panels found for figure Figure 9 (1855) in paper 10.1111/tra.12151'\n",
      "number of figures in  1567 10.1111/tra.12151 2\n",
      "counted 83 panels.\n",
      "b'1 panels found for figure Figure 1 (1872) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 2 (1926) in paper 10.1111/tra.12185'\n",
      "b'2 panels found for figure Figure 3 (1973) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 4 (2027) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 5 (2054) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 6 (2109) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 7 (2145) in paper 10.1111/tra.12185'\n",
      "b'4 panels found for figure Figure 8 (2188) in paper 10.1111/tra.12185'\n",
      "b'0 panels found for figure Figure 9 (2253) in paper 10.1111/tra.12185'\n",
      "number of figures in  1871 10.1111/tra.12185 3\n",
      "counted 90 panels.\n",
      "b'1 panels found for figure Figure 1 (2256) in paper 10.15252/msb.20145117'\n",
      "b'0 panels found for figure Figure 2 (2274) in paper 10.15252/msb.20145117'\n",
      "b'3 panels found for figure Figure 3 (2276) in paper 10.15252/msb.20145117'\n",
      "b'3 panels found for figure Figure 4 (2320) in paper 10.15252/msb.20145117'\n",
      "b'3 panels found for figure Figure 5 (2354) in paper 10.15252/msb.20145117'\n",
      "b'0 panels found for figure Figure 6 (2402) in paper 10.15252/msb.20145117'\n",
      "number of figures in  2255 10.15252/msb.20145117 4\n",
      "counted 100 panels.\n",
      "b'3 panels found for figure Figure 1 (2405) in paper 10.1002/eji.201242552'\n",
      "b'0 panels found for figure Figure 2 (2442) in paper 10.1002/eji.201242552'\n",
      "b'0 panels found for figure Figure 3 (2479) in paper 10.1002/eji.201242552'\n",
      "b'1 panels found for figure Figure 4 (2504) in paper 10.1002/eji.201242552'\n",
      "b'1 panels found for figure Figure 5 (2521) in paper 10.1002/eji.201242552'\n",
      "b'0 panels found for figure Figure 6 (2540) in paper 10.1002/eji.201242552'\n",
      "number of figures in  2404 10.1002/eji.201242552 3\n",
      "counted 105 panels.\n",
      "b'0 panels found for figure Figure 1 (2570) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 2 (2591) in paper 10.1002/eji.201242835'\n",
      "b'1 panels found for figure Figure 3 (2632) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 4 (2655) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 5 (2671) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 6 (2691) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 7 (2735) in paper 10.1002/eji.201242835'\n",
      "b'0 panels found for figure Figure 8 (2767) in paper 10.1002/eji.201242835'\n",
      "number of figures in  2569 10.1002/eji.201242835 1\n",
      "counted 106 panels.\n",
      "b'0 panels found for figure Figure 1 (2785) in paper 10.1038/emboj.2010.285'\n",
      "b'0 panels found for figure Figure 2 (2856) in paper 10.1038/emboj.2010.285'\n",
      "b'0 panels found for figure Figure 3 (2944) in paper 10.1038/emboj.2010.285'\n",
      "b'1 panels found for figure Figure 4 (3007) in paper 10.1038/emboj.2010.285'\n",
      "b'0 panels found for figure Figure 5 (3087) in paper 10.1038/emboj.2010.285'\n",
      "b'2 panels found for figure Figure 6 (3167) in paper 10.1038/emboj.2010.285'\n",
      "b'1 panels found for figure Figure 7 (3239) in paper 10.1038/emboj.2010.285'\n",
      "b'1 panels found for figure Figure 8 (3270) in paper 10.1038/emboj.2010.285'\n",
      "b'0 panels found for figure Figure 9 (3313) in paper 10.1038/emboj.2010.285'\n",
      "number of figures in  2784 10.1038/emboj.2010.285 4\n",
      "counted 111 panels.\n",
      "b'2 panels found for figure Figure 1 (3408) in paper 10.1002/embj.201385902'\n",
      "b'3 panels found for figure Figure 2 (3445) in paper 10.1002/embj.201385902'\n",
      "b'6 panels found for figure Figure 3 (3496) in paper 10.1002/embj.201385902'\n",
      "b'3 panels found for figure Figure 4 (3615) in paper 10.1002/embj.201385902'\n",
      "b'2 panels found for figure Figure 5 (3679) in paper 10.1002/embj.201385902'\n",
      "b'3 panels found for figure Figure 6 (3722) in paper 10.1002/embj.201385902'\n",
      "b'1 panels found for figure Figure 7 (3786) in paper 10.1002/embj.201385902'\n",
      "number of figures in  3407 10.1002/embj.201385902 7\n",
      "counted 131 panels.\n",
      "b'5 panels found for figure Figure 1 (3838) in paper 10.1002/embr.201438501'\n",
      "b'6 panels found for figure Figure 2 (3909) in paper 10.1002/embr.201438501'\n",
      "b'7 panels found for figure Figure 3 (4049) in paper 10.1002/embr.201438501'\n",
      "b'3 panels found for figure Figure 4 (4207) in paper 10.1002/embr.201438501'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of figures in  3837 10.1002/embr.201438501 4\n",
      "counted 152 panels.\n",
      "b'0 panels found for figure Figure 1 (4294) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 2 (4317) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 3 (4348) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 4 (4367) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 5 (4400) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 6 (4429) in paper 10.1002/emmm.201201443'\n",
      "b'0 panels found for figure Figure 7 (4446) in paper 10.1002/emmm.201201443'\n",
      "number of figures in  4293 10.1002/emmm.201201443 0\n",
      "counted 152 panels.\n",
      "b'6 panels found for figure Figure 1 (4478) in paper 10.1002/emmm.201303356'\n",
      "b'1 panels found for figure Figure 2 (4538) in paper 10.1002/emmm.201303356'\n",
      "b'2 panels found for figure Figure 3 (4573) in paper 10.1002/emmm.201303356'\n",
      "b'1 panels found for figure Figure 4 (4607) in paper 10.1002/emmm.201303356'\n",
      "b'0 panels found for figure Figure 5 (4633) in paper 10.1002/emmm.201303356'\n",
      "b'1 panels found for figure Figure 6 (4649) in paper 10.1002/emmm.201303356'\n",
      "b'0 panels found for figure Figure 7 (4689) in paper 10.1002/emmm.201303356'\n",
      "b'4 panels found for figure Figure 8 (4705) in paper 10.1002/emmm.201303356'\n",
      "b'2 panels found for figure Figure 9 (4758) in paper 10.1002/emmm.201303356'\n",
      "number of figures in  4477 10.1002/emmm.201303356 7\n",
      "counted 169 panels.\n",
      "b'0 panels found for figure Figure 1 (4788) in paper 10.15252/emmm.201303671'\n",
      "b'2 panels found for figure Figure 2 (4871) in paper 10.15252/emmm.201303671'\n",
      "b'1 panels found for figure Figure 3 (4927) in paper 10.15252/emmm.201303671'\n",
      "b'0 panels found for figure Figure 4 (4991) in paper 10.15252/emmm.201303671'\n",
      "b'0 panels found for figure Figure 5 (5036) in paper 10.15252/emmm.201303671'\n",
      "b'0 panels found for figure Figure 6 (5090) in paper 10.15252/emmm.201303671'\n",
      "b'2 panels found for figure Figure 7 (5137) in paper 10.15252/emmm.201303671'\n",
      "b'0 panels found for figure Figure 8 (5226) in paper 10.15252/emmm.201303671'\n",
      "b'0 panels found for figure Figure 9 (5301) in paper 10.15252/emmm.201303671'\n",
      "number of figures in  4787 10.15252/emmm.201303671 3\n",
      "counted 174 panels.\n",
      "b'0 panels found for figure Figure 1 (5353) in paper 10.1038/ismej.2014.51'\n",
      "b'1 panels found for figure Figure 2 (5354) in paper 10.1038/ismej.2014.51'\n",
      "b'4 panels found for figure Figure 3 (5365) in paper 10.1038/ismej.2014.51'\n",
      "b'3 panels found for figure Figure 4 (5433) in paper 10.1038/ismej.2014.51'\n",
      "b'1 panels found for figure Figure 5 (5490) in paper 10.1038/ismej.2014.51'\n",
      "b'1 panels found for figure Figure 6 (5515) in paper 10.1038/ismej.2014.51'\n",
      "b'2 panels found for figure Figure 7 (5534) in paper 10.1038/ismej.2014.51'\n",
      "b'2 panels found for figure Figure 8 (5570) in paper 10.1038/ismej.2014.51'\n",
      "number of figures in  5352 10.1038/ismej.2014.51 7\n",
      "counted 188 panels.\n",
      "b'1 panels found for figure Figure 1 (5594) in paper 10.1038/nature11895'\n",
      "b'0 panels found for figure Figure 2 (5633) in paper 10.1038/nature11895'\n",
      "b'1 panels found for figure Figure 3 (5663) in paper 10.1038/nature11895'\n",
      "b'0 panels found for figure Figure 4 (5717) in paper 10.1038/nature11895'\n",
      "b'2 panels found for figure Figure 5 (5723) in paper 10.1038/nature11895'\n",
      "number of figures in  5593 10.1038/nature11895 3\n",
      "counted 192 panels.\n",
      "\n",
      "number of raw_examples\n",
      " 20\n",
      "N = 64\n",
      "generating 64*5 x 22 x 1220 tensor.\n",
      "[############################################################] 100% ...sampling\n",
      "length of the 64 examples selected:\n",
      "866.640625 +/- 538.6376342773438 (min = 140, max = 2636)\n",
      "Exec time for 'sample': 6.333s\n",
      "N = 14\n",
      "generating 14*5 x 22 x 1220 tensor.\n",
      "[#############################################################] 101% ...sampling\n",
      "length of the 14 examples selected:\n",
      "634.0714285714286 +/- 381.0181579589844 (min = 304, max = 1688)\n",
      "Exec time for 'sample': 1.283s\n",
      "saved 5X_L1200_small_molecule_w_train.pyth (size: 8589113)\n",
      "saved 5X_L1200_small_molecule_w_train_textcoded.pyth (size: 12493113)\n",
      "saved 5X_L1200_small_molecule_w_train.txt (size: 396430)\n",
      "saved 5X_L1200_small_molecule_w_train.prov (size: 7975)\n",
      "saved 5X_L1200_small_molecule_w_test.pyth (size: 1879112)\n",
      "saved 5X_L1200_small_molecule_w_test_textcoded.pyth (size: 2733112)\n",
      "saved 5X_L1200_small_molecule_w_test.txt (size: 85908)\n",
      "saved 5X_L1200_small_molecule_w_test.prov (size: 1740)\n"
     ]
    }
   ],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y molecule -f 5X_L1200_small_molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene and proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y protein,gene -f 5X_L1200_protein_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellular components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X10 -y subcellular -f 10X_L1200_subcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y cell -f 5X_L1200_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tissue & Organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y tissue -f 5X_L1200_tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y organism -f 5X_L1200_organism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.sdgraph2th -l1000 -L1200 -X5 -y exp_assay -f 5X_L1200_exp_assay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseases\n",
    "Using a corpus in the brat format. Note that we need to use the module `ann2th`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.datagen.ann2th -L1200 -X5 -f 5X_L1200_disease compendium/ncbi_disease/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Moving training data to Amazon EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_small_molecule_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_gene_protein_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_subcell_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_cell_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_tissue_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_organism_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_exp_assay_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i basicLinuxAMI.pem 5X_L1200_disease_train.zip ec2-user@smtag-web:/efs/smtag/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Training models on multi-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small molecule model\n",
    "120 epoch with learning rate 0.01 and batch size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python meta -E120 -Z128 -R0.01 -o small_molecule -f 5X_L1200_small_molecule_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene product model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cellular component model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue and organ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organism model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental assay model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles of gene products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles of small molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporter gene products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt[namebase]=5X_L1200_small_molecule_w_train\n",
      "opt[learning_rate]=0.01\n",
      "opt[epochs]=120\n",
      "opt[minibatch_size]=128\n",
      "opt[selected_features]=['geneprod']\n",
      "opt[collapsed_features]=[]\n",
      "opt[overlap_features]=[]\n",
      "opt[features_as_input]=[]\n",
      "opt[nf_table]=[8, 8, 8]\n",
      "opt[pool_table]=[2, 2, 2]\n",
      "opt[kernel_table]=[6, 6, 6]\n",
      "opt[dropout]=0.1\n",
      "opt[validation_fraction]=0.2\n",
      "nf.output= 1\n",
      "nf.input= 32\n",
      "index_of_collapsed_feature= None\n",
      "index_of_overlap_feature None\n",
      "concept2index self.selected_features [21]\n",
      "concept2index self.collapsed_features []\n",
      "concept2index self.overlap_features []\n",
      "Loading ./data/5X_L1200_small_molecule_w_train.pyth as features for the dataset.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/lemberger/Documents/code/py-smtag/smtag/train/meta.py\", line 116, in <module>\n",
      "    main()\n",
      "  File \"/Users/lemberger/Documents/code/py-smtag/smtag/train/meta.py\", line 101, in main\n",
      "    datasets = ldr.prepare_datasets(opt['namebase'])\n",
      "  File \"/Users/lemberger/Documents/code/py-smtag/smtag/train/loader.py\", line 127, in prepare_datasets\n",
      "    raw_dataset.from_files(file_basename)\n",
      "  File \"/Users/lemberger/Documents/code/py-smtag/smtag/train/loader.py\", line 50, in from_files\n",
      "    self.output = torch.load(features_filename).float()\n",
      "  File \"/Users/lemberger/Documents/code/py-smtag/.venv/lib/python3.6/site-packages/torch/serialization.py\", line 301, in load\n",
      "    f = open(f, 'rb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './data/5X_L1200_small_molecule_w_train.pyth'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "python -m smtag.train.meta -f 5X_L1200_small_molecule_w_train -E120 -R0.01 -Z128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Benchmark on the test set, without tokenization (option `-T`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m smtag.train.evaluate -f 5X_L1200_small_molecule_w_test -m 5X_L1200_small_molecule -T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Copy models locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Evaluate models with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
